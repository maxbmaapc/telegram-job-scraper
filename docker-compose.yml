# Docker Compose configuration for Telegram Job Scraper

services:
  telegram-scraper:
    image: telegram-job-scraper:latest
    container_name: telegram-job-scraper
    restart: unless-stopped
    environment:
      # Telegram API Credentials (set these in .env file)
      - API_ID=${API_ID}
      - API_HASH=${API_HASH}
      - AUTH_METHOD=${AUTH_METHOD:-user}
      - BOT_TOKEN=${BOT_TOKEN}
      - PHONE_NUMBER=${PHONE_NUMBER}

      # Target Channels
      - TARGET_CHANNELS=${TARGET_CHANNELS}

      # Filter Settings
      - FILTER_KEYWORDS=${FILTER_KEYWORDS}
      - DATE_FILTER_HOURS=${DATE_FILTER_HOURS:-24}

      # Output Settings
      - OUTPUT_METHOD=${OUTPUT_METHOD:-database}
      - SEND_TO_SELF=${SEND_TO_SELF:-false}

      # Target Personal Account (when SEND_TO_SELF=false)
      - TARGET_USER_ID=${TARGET_USER_ID}
      - TARGET_USERNAME=${TARGET_USERNAME}
      - TARGET_PHONE_NUMBER=${TARGET_PHONE_NUMBER}

      # Database Settings
      - DATABASE_PATH=/app/data/jobs.db

      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FILE=/app/logs/telegram_scraper.log
      - LOG_JSON=${LOG_JSON:-false}
      - LOG_COLORS=${LOG_COLORS:-true}

      # Web UI Settings
      - WEB_HOST=0.0.0.0
      - WEB_PORT=5000

      # Rate Limiting
      - MESSAGE_DELAY_MIN=${MESSAGE_DELAY_MIN:-2.0}
      - MESSAGE_DELAY_MAX=${MESSAGE_DELAY_MAX:-3.0}

      # Scheduling
      - SCHEDULE_INTERVAL_MINUTES=${SCHEDULE_INTERVAL_MINUTES:-30}
      - SCHEDULE_START_TIME=${SCHEDULE_START_TIME}
      - SCHEDULE_END_TIME=${SCHEDULE_END_TIME}
      - SCHEDULE_DAYS_OF_WEEK=${SCHEDULE_DAYS_OF_WEEK:-0,1,2,3,4,5,6}
      - SCHEDULE_MAX_RUNS_PER_DAY=${SCHEDULE_MAX_RUNS_PER_DAY:-0}

      # Performance
      - BATCH_SIZE=${BATCH_SIZE:-50}
      - MAX_RETRIES=${MAX_RETRIES:-3}

      # Security
      - ENABLE_SSL_VERIFICATION=${ENABLE_SSL_VERIFICATION:-true}

    volumes:
      # Persist data and logs
      - ./data:/app/data
      - ./logs:/app/logs
      - ./sessions:/app/sessions

      # Mount config files (optional)
      - ./config:/app/config:ro

    ports:
      - "5001:5000" # Web UI

    networks:
      - scraper-network

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Resource limits
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Optional: Redis for caching and session storage
  redis:
    image: redis:7-alpine
    container_name: scraper-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - scraper-network
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: scraper-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - telegram-scraper
    networks:
      - scraper-network
    profiles:
      - production

  # Development override service
  telegram-scraper-dev:
    extends: telegram-scraper
    profiles:
      - development
    environment:
      - LOG_LEVEL=DEBUG
      - LOG_COLORS=true
    volumes:
      - ./src:/app/src # Mount source code for development
      - ./data:/app/data
      - ./logs:/app/logs
      - ./sessions:/app/sessions

networks:
  scraper-network:
    driver: bridge

volumes:
  redis-data:
    driver: local
